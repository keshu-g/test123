<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Audio Upload and Record</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      background-color: #f5f5f5;
      margin: 0;
      padding: 20px;
      text-align: center;
    }

    h1 {
      color: #333;
    }

    button {
      background-color: #4CAF50;
      color: white;
      padding: 10px 20px;
      border: none;
      border-radius: 5px;
      cursor: pointer;
      font-size: 16px;
      margin: 5px;
    }

    button:disabled {
      background-color: #ccc;
      cursor: not-allowed;
    }

    #audioFileInput, #fileNameDisplay, #transcriptOutput, #statusMessage {
      display: block;
      margin: 10px auto;
    }

    #fileNameDisplay {
      font-style: italic;
      color: #666;
    }

    #transcriptOutput {
      width: 80%;
      padding: 10px;
      border-radius: 5px;
      border: 1px solid #ccc;
      margin-top: 20px;
    }

    #statusMessage {
      font-size: 14px;
      color: #666;
      margin-top: 20px;
    }

    textarea {
      font-family: inherit;
      font-size: 14px;
      resize: vertical;
    }

    button:hover:not(:disabled) {
      background-color: #45a049;
    }
  </style>
</head>
<body>
  <h1>Audio Upload and Record</h1>

  <!-- Upload Audio Section -->
  <button onclick="document.getElementById('audioFileInput').click()">Upload Audio</button>
  <input type="file" id="audioFileInput" accept="audio/*" style="display:none">
  <span id="fileNameDisplay">No file chosen</span>
  <button id="transcriptBtn" disabled>Transcript</button>

  <br><br>

  <!-- Record Audio Section -->
  <button id="recordAudioBtn">Record Audio</button>
  <button id="stopRecordingBtn" disabled>Stop Recording</button>

  <br><br>

  <!-- Status Message -->
  <p id="statusMessage"></p>

  <!-- Transcript Output and Actions -->
  <textarea id="transcriptOutput" rows="10" cols="100" disabled></textarea>
  <br>
  <button id="editTranscriptBtn" disabled>Edit Transcript</button>
  <button id="copyTranscriptBtn" disabled>Copy to Clipboard</button>
  <button id="reloadPageBtn">Reload Page</button>

  <script>
    document.addEventListener('DOMContentLoaded', () => {
      const audioFileInput = document.getElementById('audioFileInput');
      const transcriptBtn = document.getElementById('transcriptBtn');
      const recordAudioBtn = document.getElementById('recordAudioBtn');
      const stopRecordingBtn = document.getElementById('stopRecordingBtn');
      const fileNameDisplay = document.getElementById('fileNameDisplay');
      const statusMessage = document.getElementById('statusMessage');
      const transcriptOutput = document.getElementById('transcriptOutput');
      const editTranscriptBtn = document.getElementById('editTranscriptBtn');
      const copyTranscriptBtn = document.getElementById('copyTranscriptBtn');
      const reloadPageBtn = document.getElementById('reloadPageBtn');

      let mediaRecorder;
      let recordedChunks = [];
      let isRecording = false;

      function handleError(error) {
        transcriptOutput.value = `Error: ${error.message}`;
        statusMessage.textContent = "";
        toggleButtons(true, true, false, false, false);
      }

      function toggleButtons(transcriptEnabled, recordEnabled, stopEnabled, editEnabled, copyEnabled) {
        transcriptBtn.disabled = !transcriptEnabled;
        recordAudioBtn.disabled = !recordEnabled;
        stopRecordingBtn.disabled = !stopEnabled;
        editTranscriptBtn.disabled = !editEnabled;
        copyTranscriptBtn.disabled = !copyEnabled;
      }

      async function uploadAudio(audioBlob) {
        const formData = new FormData();
        formData.append('files', audioBlob);

        transcriptOutput.value = "";

        statusMessage.textContent = "Please wait, we are transcribing your audio note. Transcription time depends on the length of the audio.";

        try {
          const response = await fetch('https://49.50.119.73.nip.io/whisper', {
            method: 'POST',
            body: formData,
          });

          if (response.ok) {
            const result = await response.json();
            const transcript = result.results[0].transcript;
            transcriptOutput.value = transcript;
            statusMessage.textContent = "Transcription complete!";
            toggleButtons(true, true, false, true, true);
          } else {
            handleError(new Error(response.statusText));
          }
        } catch (error) {
          handleError(error);
        }
      }

      // File upload handling
      audioFileInput.addEventListener('change', () => {
        const fileName = audioFileInput.files.length > 0 ? audioFileInput.files[0].name : 'No file chosen';
        fileNameDisplay.textContent = fileName;
        toggleButtons(!!audioFileInput.files.length, true, false, false, false);
      });

      transcriptBtn.addEventListener('click', async () => {
        if (audioFileInput.files.length > 0) {
          statusMessage.textContent = "Please wait, we are transcribing your audio note. Transcription time depends on the length of the audio.";
          transcriptBtn.disabled = true;
          recordAudioBtn.disabled = true;
          await uploadAudio(audioFileInput.files[0]);
        }
      });

      // Audio recording handling
      recordAudioBtn.addEventListener('click', async () => {
        try {
          const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
          mediaRecorder = new MediaRecorder(stream);

          mediaRecorder.ondataavailable = (event) => recordedChunks.push(event.data);
          mediaRecorder.onstop = async () => {
            const audioBlob = new Blob(recordedChunks, { type: 'audio/wav' });
            recordedChunks = []; // Reset for next recording
            await uploadAudio(audioBlob);
            isRecording = false;
            toggleButtons(true, true, false, true, true);
          };

          mediaRecorder.start();
          isRecording = true;
          statusMessage.textContent = "Recording... Please start speaking.";
          toggleButtons(false, false, true, false, false);
        } catch (error) {
          handleError(error);
        }
      });

      stopRecordingBtn.addEventListener('click', () => {
        if (mediaRecorder && isRecording) {
          mediaRecorder.stop();
          statusMessage.textContent = "Please wait, we are transcribing your audio note. Transcription time depends on the length of the audio.";
        }
      });

      // Transcript editing and copying
      editTranscriptBtn.addEventListener('click', () => {
        transcriptOutput.disabled = false;
        editTranscriptBtn.disabled = true;
        copyTranscriptBtn.disabled = false;
      });

      copyTranscriptBtn.addEventListener('click', () => {
        transcriptOutput.select();
        document.execCommand('copy');
        alert('Transcript copied to clipboard!');
      });

      // Page reload
      reloadPageBtn.addEventListener('click', () => {
        window.location.reload();
      });
    });
  </script>
</body>
</html>
